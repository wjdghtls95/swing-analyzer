import httpx
from typing import Optional
import logging
from app.schemas.diagnosis_dto import DiagnosisResult

logger = logging.getLogger(__name__)

class LLMGatewayClient:
    """LLM Gatewayì™€ í†µì‹ í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸"""

    def __init__(
        self,
        gateway_url: str,
        provider: str = "noop",
        model: str = "gpt-4o-mini",
        api_key: Optional[str] = None,
        timeout: int = 30
    ):
        """
        Args:
            gateway_url: LLM Gateway ì„œë²„ URL (ì˜ˆ: http://localhost:3030)
            provider: LLM ì œê³µì (noop, openai, anthropic ë“±)
            model: ëª¨ë¸ëª…
            api_key: API í‚¤ (optional, Gatewayì—ì„œ ê´€ë¦¬í•  ìˆ˜ë„ ìˆìŒ)
            timeout: íƒ€ì„ì•„ì›ƒ(ì´ˆ)
        """
        self.gateway_url = gateway_url.rstrip("/")
        self.provider=provider.lower()
        self.model = model
        self.api_key = api_key
        self.timeout = timeout

        if self.provider == 'noop':
            logger.info("ğŸ§ª LLM Client: NoOp ëª¨ë“œ (í…ŒìŠ¤íŠ¸ìš©, ê³¼ê¸ˆ ì—†ìŒ)")
        else:
            logger.info(f"ğŸš€ LLM Client: {provider} / {model}")


    def generate_feedback(
        self,
        diagnosis: DiagnosisResult,
        user_id: str,
        club: str,
        tone: str = "professional",
        language: str = "ko"
    ) -> str:
        """
        ì§„ë‹¨ ê²°ê³¼ ê¸°ë°˜ AI í”¼ë“œë°± ìƒì„±

        Args:
            diagnosis: ì§„ë‹¨ ê²°ê³¼
            user_id: ì‚¬ìš©ì ID
            club: í´ëŸ½ ì¢…ë¥˜
            tone: ì–´ì¡° (professional, friendly, coach)
            language: ì–¸ì–´ (ko, en)

        Returns:
            AIê°€ ìƒì„±í•œ í”¼ë“œë°± í…ìŠ¤íŠ¸
        """
        # noop ëª¨ë“œ- mock ì‘ë‹µ ì¦‰ì‹œ return
        if self.provider == "noop":
            logger.info("Noop ëª¨ë“œ: Mock ì‘ë‹µ ë°˜í™˜ (ê³¼ê¸ˆ ì—†ìŒ)")
            return self._generate_mock_feedback(diagnosis)

        # System prompt
        system_prompt = self._build_system_prompt(tone, language)

        # User prompt (ì§„ë‹¨ ìš”ì•½)
        user_prompt = self._build_user_prompt(diagnosis, club)

        # LLM Gateway í˜¸ì¶œ
        try:
            response = httpx.post(
                f"{self.gateway_url}/api/chat",
                json={
                    "provider": self.provider,
                    "model": self.model,
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    "user_id": user_id,
                    "temperature": 0.7,
                    "max_tokens": 500
                },
                headers={"X-API-Key": self.api_key} if self.api_key else {},
                timeout=self.timeout
            )
            response.raise_for_status()

            result = response.json()
            return result.get("content", "í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨")

        except httpx.HTTPError as e:
            # Fallback: ë£° ê¸°ë°˜ í”¼ë“œë°±
            return self._fallback_feedback(diagnosis)

    def _build_system_prompt(self, tone: str, language: str) -> str:
        """System prompt ìƒì„±"""
        tone_map = {
            "professional": "ì „ë¬¸ì ì´ê³  ê°ê´€ì ì¸",
            "friendly": "ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ”",
            "coach": "ì½”ì¹˜ì²˜ëŸ¼ êµ¬ì²´ì ì¸ ì‹¤ì²œ ë°©ì•ˆì„ ì œì‹œí•˜ëŠ”"
        }

        tone_desc = tone_map.get(tone, "ì „ë¬¸ì ì´ê³  ê°ê´€ì ì¸")

        if language == "ko":
            return f"""ë‹¹ì‹ ì€ í”„ë¡œ ê³¨í”„ ì½”ì¹˜ì…ë‹ˆë‹¤.
ìŠ¤ìœ™ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ {tone_desc} ì–´ì¡°ë¡œ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”.

ìš”êµ¬ì‚¬í•­:
- 5-8ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±
- ê°€ì¥ ì¤‘ìš”í•œ ë¬¸ì œì  2-3ê°œë§Œ ì–¸ê¸‰
- êµ¬ì²´ì ì¸ ê°œì„  ë°©ë²• ì œì‹œ
- ê¸ì •ì ì¸ ë¶€ë¶„ë„ í•¨ê»˜ ì–¸ê¸‰
"""
        else:  # English
            return f"""You are a professional golf coach.
Provide feedback based on swing analysis results in a {tone_desc} tone.

Requirements:
- Keep it concise (5-8 sentences)
- Mention only 2-3 most important issues
- Provide specific improvement methods
- Include positive aspects as well
"""

    def _build_user_prompt(self, diagnosis: DiagnosisResult, club: str) -> str:
        """User prompt (ì§„ë‹¨ ìš”ì•½) ìƒì„±"""
        lines = [f"í´ëŸ½: {club}", f"ì „ì²´ ì ìˆ˜: {diagnosis.overall_score:.1f}/100", ""]

        for d in diagnosis.diagnoses:
            lines.append(f"[{d.phase}] ì ìˆ˜: {d.score:.1f}")
            if d.issues:
                lines.append(f"  ë¬¸ì œì : {', '.join(d.issues[:2])}")  # ìµœëŒ€ 2ê°œë§Œ

        return "\n".join(lines)

    def _fallback_feedback(self, diagnosis: DiagnosisResult) -> str:
        """LLM ì‹¤íŒ¨ ì‹œ ë£° ê¸°ë°˜ í”¼ë“œë°±"""
        feedback_lines = [f"ìŠ¤ìœ™ ì „ì²´ ì ìˆ˜: {diagnosis.overall_score:.1f}/100"]

        # ê°€ì¥ ë‚®ì€ ì ìˆ˜ í˜ì´ì¦ˆ ì°¾ê¸°
        worst_phase = min(diagnosis.diagnoses, key=lambda d: d.score)

        feedback_lines.append(f"\nê°€ì¥ ê°œì„ ì´ í•„ìš”í•œ ë‹¨ê³„: {worst_phase.phase} (ì ìˆ˜: {worst_phase.score:.1f})")

        if worst_phase.issues:
            feedback_lines.append("\nì£¼ìš” ë¬¸ì œì :")
            for issue in worst_phase.issues[:2]:
                feedback_lines.append(f"- {issue}")

        if worst_phase.suggestions:
            feedback_lines.append("\nê°œì„  ì œì•ˆ:")
            for suggestion in worst_phase.suggestions[:2]:
                feedback_lines.append(f"- {suggestion}")

        return "\n".join(feedback_lines)

    def _generate_mock_feedback(self, diagnosis: DiagnosisResult) -> str:
        """
        Noop ëª¨ë“œìš© Mock í”¼ë“œë°± ìƒì„±

        Args:
            diagnosis: ì§„ë‹¨ ê²°ê³¼

        Returns:
            Mock í”¼ë“œë°± í…ìŠ¤íŠ¸
        """
        feedback_lines = [
            "[í…ŒìŠ¤íŠ¸ ëª¨ë“œ - NoOp LLM]",
            "",
            f"âœ… ìŠ¤ìœ™ ë¶„ì„ì´ ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            f"ì „ì²´ ì ìˆ˜: {diagnosis.overall_score:.1f}/100",
            ""
        ]

        # ê°€ì¥ ë‚®ì€ ì ìˆ˜ í˜ì´ì¦ˆ ì°¾ê¸°
        if diagnosis.diagnoses:
            worst_phase = min(diagnosis.diagnoses, key=lambda d: d.score)
            feedback_lines.append(f"ê°œì„ ì´ í•„ìš”í•œ ë‹¨ê³„: {worst_phase.phase} (ì ìˆ˜: {worst_phase.score:.1f})")

            if worst_phase.issues:
                feedback_lines.append("")
                feedback_lines.append("ì£¼ìš” ë¬¸ì œì :")
                for issue in worst_phase.issues[:2]:
                    feedback_lines.append(f"- {issue}")

        feedback_lines.extend([
            "",
            "í˜„ì¬ëŠ” í…ŒìŠ¤íŠ¸ ëª¨ë“œë¡œ, ì‹¤ì œ LLM APIë¥¼ í˜¸ì¶œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
            "ê³¼ê¸ˆì´ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
            "",
            "ì‹¤ì œ AI í”¼ë“œë°±ì„ ë°›ìœ¼ë ¤ë©´:",
            "1. Swagger UIì—ì„œ llm_providerë¥¼ 'openai'ë¡œ ë³€ê²½",
            "2. llm_modelì„ 'gpt-4o-mini' ë“±ìœ¼ë¡œ ì„¤ì •",
            "3. Execute ì‹¤í–‰"
        ])