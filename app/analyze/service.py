from __future__ import annotations
from fastapi import HTTPException
import os, shutil, uuid, time, json, requests, logging, glob
from typing import Optional, Dict, List, Tuple
from pathlib import Path

from app.analyze.extractor import PoseExtractor
from app.analyze.angle import (
    calculate_elbow_angle,
    calculate_knee_angle,
    angles_at_frame,
)
from app.analyze.phase import detect_phases
from app.analyze.schema import NormMode, ClubType
from app.analyze.preprocess import normalize_video, normalize_video_pro
from app.analyze.results_builder import build_result
from app.analyze.diagnosis import build_phase_diagnosis

from app.config.settings import settings

from app.llm.client import DelegateLLMClient

from app.utils.resource_finder import rf
from app.utils.types.types import Message
from app.utils.thresholds_utils import (
    qc_thresholds_usable,
    adapt_bins_to_ranges,
)

_llm = DelegateLLMClient()

# ---------- ë¡œê±° ----------
logger = logging.getLogger(__name__)
if not logging.getLogger().handlers:
    logging.basicConfig(
        level=logging.INFO, format="%(asctime)s %(levelname)s %(name)s: %(message)s"
    )

# ---------- ë‚´ë¶€ ë¡œê¹… ë””ë ‰í† ë¦¬ ----------
_LOG_DIR = settings.LOG_DIR
_LOG_DIR.mkdir(parents=True, exist_ok=True)

# REQUIRED_KEYSëŠ” settings ì—ì„œë§Œ ê´€ë¦¬
REQUIRED_KEYS = set(settings.THRESH_REQUIRED_KEYS)


# ---------- ë©”ì¸ íŒŒì´í”„ë¼ì¸ ----------
def analyze_swing(
    file_path: str,
    side: str = "right",
    min_vis: float = 0.5,
    norm_mode: NormMode = NormMode.auto,
    club: Optional[ClubType] = None,
    # LLM ì˜µì…˜: ê¸°ë³¸ê°’/ì²´ì¸/í† í° ë“±ì€ settings ì—ì„œë§Œ ê´€ë¦¬
    llm_provider: str = settings.LLM_DEFAULT_PROVIDER,
    llm_model: Optional[str] = None,
    llm_api_key: Optional[str] = None,
    llm_extra: Optional[Dict[str, any]] = None,
) -> dict:
    """
    íŒŒì´í”„ ë¼ì¸
    1) ì „ì²˜ë¦¬ â†’ 2) í¬ì¦ˆ ì¶”ì¶œ â†’ 3) í‰ê·  ë©”íŠ¸ë¦­ ê³„ì‚° â†’ 4) í˜ì´ì¦ˆë³„ ì§€í‘œ â†’ 5) thresholds ë¡œë”©/ì ìš© â†’ 6) ë£° ê¸°ë°˜ ì§„ë‹¨ -> 7) LLM ìš”ì•½/í–‰ë™ ê°€ì´ë“œ -> 8) ì‘ë‹µ
    """
    llm_extra = llm_extra or {}

    # 1) ì „ì²˜ë¦¬ (ì˜ìƒ í‘œì¤€í™”)
    try:
        norm_path, used_mode, preprocess_ms = _do_preprocess(file_path, norm_mode)
        norm_path = str(norm_path)
    except FileNotFoundError as e:
        raise HTTPException(status_code=404, detail=f"Input not found: {e}")
    except RuntimeError as e:
        raise HTTPException(status_code=500, detail=f"Preprocess failed: {e}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Unexpected error: {e}")

    # 2) í¬ì¦ˆ ì¶”ì¶œ
    extractor = PoseExtractor(step=getattr(settings, "POSE_FRAME_STEP", 3))
    landmarks_np, landmarks, total_seen = extractor.extract_from_video(norm_path)

    # 3) í‰ê·  ë©”íŠ¸ë¦­
    elbow_angle = calculate_elbow_angle(landmarks, side=side, min_vis=min_vis)
    knee_angle = calculate_knee_angle(landmarks, side=side, min_vis=min_vis)
    metrics = {
        "elbow_avg": float(elbow_angle) if elbow_angle == elbow_angle else float("nan"),
        "knee_avg": float(knee_angle) if knee_angle == knee_angle else float("nan"),
    }

    # 4) í˜ì´ì¦ˆë³„ ì§€í‘œ
    phase_method = settings.PHASE_METHOD
    phases = detect_phases(landmarks, phase_method)

    # ë™ì•Œ í˜ì´ì¦ˆ ì¸ë±ìŠ¤ ì¤‘ë³µ ì œê±°(P2 â†’ P9 ìš°ì„  ì±„íƒ)
    phases = _dedupe_phases(phases)

    phase_metrics: Dict[str, Dict[str, float]] = {}
    for key, idx in phases.items():
        if idx is None or idx >= len(landmarks):
            phase_metrics[key] = {}
            continue
        frame = landmarks[idx]
        phase_metrics[key] = angles_at_frame(frame, side=side)

    # 5) thresholds ë¡œë“œ / ë³€í™˜ /í˜ì´ì¦ˆë³„ ì§„ë‹¨
    # thresholds = _load_thresholds()
    thresholds_raw = _load_thresholds(by="phase")
    thresholds_for_rules = _adapt_thresholds_bins_to_ranges(
        thresholds_raw, qlow=settings.THRESH_QLOW, qhigh=settings.THRESH_QHIGH
    )

    # settings.THRESH_METRICSê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê´€ì¸¡ëœ í‚¤ë¡œ ë„ì¶œ
    metrics_for_label: List[str] = settings.THRESH_METRICS or _infer_metrics_from_phase(
        phase_metrics
    )

    club_key = club.value if hasattr(club, "value") else (club or "")
    diagnosis_by_phase = build_phase_diagnosis(
        phase_metrics=phase_metrics,
        club=club_key,
        thresholds=thresholds_for_rules,
        metrics=metrics_for_label,
    )

    try:
        logger.info(f"[DEBUG] phase_metrics: {json.dumps(phase_metrics, indent=2)}")
    except Exception:
        logger.info(f"[DEBUG] phase_metrics (non-serializable): {phase_metrics}")

    try:
        logger.info(f"[DEBUG] diagnosis_by_phase: {json.dumps(diagnosis_by_phase, indent=2)}")
    except Exception:
        logger.info(f"[DEBUG] diagnosis_by_phase (non-serializable): {diagnosis_by_phase}")

    # 6) LLM ìš”ì•½ (gateway / sdk ëª¨ë‘ Delegateì— ìœ„ì„)
    #   - í”„ë¡¬í”„íŠ¸ë„ í•˜ë“œì½”ë”© ê¸ˆì§€í•˜ê³  ì‹¶ë‹¤ë©´ settingsì— ìƒìˆ˜ë¡œ ë¹¼ì„œ ê´€ë¦¬ ê°€ëŠ¥
    delegate_provider, delegate_extra = _map_to_delegate(llm_provider, llm_extra)
    llm_text = "[LLM unavailable]"
    provider_used = llm_provider

    # --- A. NestJS ê²Œì´íŠ¸ì›¨ì´("gateway")ë¥¼ ì‚¬ìš©í•˜ë¼ê³  ìš”ì²­ë°›ì€ ê²½ìš° ---
    if llm_provider == "gateway":
        logger.info(f"[LLM] Calling NestJS Gateway (/chat) at: {settings.NEST_GATEWAY_CHAT_URL}")
        provider_used = "gateway (nest)"

        # 1. [ë²ˆì—­] NestJSì˜ 'AnalysisDataDto' í˜•ì‹ìœ¼ë¡œ "ë²ˆì—­"
        # (ì´ ë§¤í•‘ì€ NestJS DTOì™€ Python ë°ì´í„° êµ¬ì¡°ì— ë§ê²Œ ì •í™•íˆ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.)
        try:
            analysis_data_for_nest = {
                # ì˜ˆì‹œ: P4(íƒ‘)ì˜ 'body_angle' ê°’ì„ 'backswingAngle' í‚¤ì— ë§¤í•‘
                "backswingAngle": phase_metrics.get("P4", {}).get("shoulder_turn", 0),
                # ì˜ˆì‹œ: P6(ë‹¤ìš´)ì˜ 'body_angle' ê°’ì„ 'downswingAngle' í‚¤ì— ë§¤í•‘
                "downswingAngle": phase_metrics.get("P6", {}).get("shoulder_turn", 0),
                # ì˜ˆì‹œ: P7(ì„íŒ©íŠ¸)ì˜ 'body_angle' ê°’ì„ 'impactAngle' í‚¤ì— ë§¤í•‘
                "impactAngle": phase_metrics.get("P7", {}).get("spine_tilt", 0),

                # [â˜…] 'errors'ê°€ í•„ìš”í•œ ì´ìœ :
                # P7(ì„íŒ©íŠ¸)ì—ì„œ ì§„ë‹¨ëœ ë¬¸ì œì ('label') ëª©ë¡ì„ LLMì—ê²Œ ì „ë‹¬
                "errors": [diag["label"] for diag in diagnosis_by_phase.get("P7", []) if "label" in diag]
            }
        except Exception as e:
            logger.error(f"[NEST_GW] Failed to translate analysis data: {e}")
            # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ, DTO ìœ íš¨ì„± ê²€ì‚¬ë¥¼ í†µê³¼í•  ê¸°ë³¸ê°’ ì „ì†¡
            analysis_data_for_nest = {
                "backswingAngle": 0, "downswingAngle": 0, "impactAngle": 0, "errors": ["translation_failed"]
            }

        # 2. [ë²ˆì—­] NestJSë¡œ ë³´ë‚¼ í”„ë¡¬í”„íŠ¸ (ë°ì´í„°ë¥¼ ì œì™¸í•œ ìˆœìˆ˜ ì§ˆë¬¸)
        prompt_for_nest = (
            f"Side: {side}, Club: {club_key or 'unknown'}\n"
            "ë‚´ ìŠ¤ìœ™ ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ 1-2ë¬¸ì¥ ìš”ì•½ê³¼ 3ê°œ ì´í•˜ì˜ ì‹¤ì²œ ë°©ì•ˆì„ í•œêµ­ì–´ë¡œ ì•Œë ¤ì¤˜. (ê° 15ë‹¨ì–´ ì´ë‚´)"
        )

        # 3. [ë²ˆì—­] NestJS /chat DTO í˜ì´ë¡œë“œ(ì „ì†¡í•  JSON) êµ¬ì„±
        nest_chat_dto = {
            "provider": delegate_extra.get("vendor", "openai"),  # ê²Œì´íŠ¸ì›¨ì´ê°€ ì‚¬ìš©í•  ì‹¤ì œ LLM
            "model": (llm_model or settings.LLM_DEFAULT_MODEL),
            "prompt": prompt_for_nest,
            "analysisData": analysis_data_for_nest,  # ğŸ‘ˆ 1ë²ˆì—ì„œ "ë²ˆì—­í•œ" ë°ì´í„°
            "language": "ko"
        }

        # 4. [ì „ì†¡] NestJS ê²Œì´íŠ¸ì›¨ì´ í˜¸ì¶œ
        try:
            response = requests.post(
                settings.NEST_GATEWAY_CHAT_URL,  # ğŸ‘ˆ settings.py ì— ì„¤ì •ëœ ì£¼ì†Œ
                json=nest_chat_dto,  # ğŸ‘ˆ 3ë²ˆì—ì„œ ë§Œë“  JSON
                headers={
                    "Content-Type": "application/json",
                    "X-Internal-Api-Key": settings.NEST_INTERNAL_API_KEY  # ğŸ‘ˆ settings.py ì— ì„¤ì •ëœ í‚¤
                },
                timeout=20.0
            )

            if response.status_code == 200:
                llm_text = response.json().get("feedback", "[LLM response format error]")
            else:
                logger.warning(f"[NEST_GW] Call failed: {response.status_code} - {response.text}")
                llm_text = f"[LLM gateway error: {response.status_code}]"
        except requests.exceptions.RequestException as e:
            logger.error(f"[NEST_GW] Connection failed: {e}")
            llm_text = "[LLM connection error]"

    # --- B. ê¸°ì¡´ ë°©ì‹ ("openai", "compat" ë“±)ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ---
    else:
        logger.info(f"[LLM] Calling DelegateLLMClient with provider: {llm_provider}")
        provider_used = llm_provider

        # (ê¸°ì¡´ì˜ messages, user_prompt, _llm.generate() í˜¸ì¶œ ì½”ë“œ... ë™ì¼)
        system_prompt = (
            "You are a concise golf swing coach. "
            "Explain issues briefly and list up to 3 actionable steps. "
            "Keep each action under 15 words."
        )

        user_prompt = (
                "Phase-based diagnosis JSON (already evaluated by thresholds):\n"
                f"{json.dumps(diagnosis_by_phase, ensure_ascii=False)}\n\n"
                f"Side: {side}, Club: {club_key or 'unknown'}\n"
                "Return:\n- summary: 1-2 sentences\n- actions: bullet points (<=3)"
            )

        messages: List[Message] = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]
        try:
            llm_text = _llm.generate(
                messages,
                provider=llm_provider,
                model=(llm_model or settings.LLM_DEFAULT_MODEL),
                temperature=settings.LLM_TEMPERATURE_DEFAULT,
                max_tokens=settings.LLM_MAX_TOKENS_DEFAULT,
                timeout=90.0,
                api_key_override=llm_api_key,
                extra=delegate_extra,
            )
        except Exception as e:
            logger.warning(f"[LLM] failed: {e}")
            llm_text = "[LLM unavailable]"

    # 7) ì‘ë‹µ ì¡°ë¦½
    detected = len(landmarks)
    total = int(total_seen or detected)
    rate = round(detected / total, 3) if total else None
    swing_id = os.path.basename(file_path).split("_")[0]

    result = build_result(
        swing_id=swing_id,
        file_path=file_path,
        side=side,
        club=club,
        used_mode=used_mode,
        preprocess_ms=preprocess_ms,
        min_vis=min_vis,
        phase_method=phase_method,
        detected=detected,
        total=total,
        rate=rate,
        metrics=metrics,  # FEê°€ ì•ˆ ì“°ë©´ results_builderì—ì„œ ë¹¼ë„ OK
        phases=phases,
        phase_metrics=phase_metrics,
        diagnosis_by_phase=diagnosis_by_phase,  # í˜ì´ì¦ˆë³„ë§Œ (AVG ì—†ìŒ)
    )

    # ë‚´ë¶€ ë¡œê¹…
    try:
        log_path = settings.LOG_DIR / f"{swing_id}_{uuid.uuid4().hex[:6]}.json"
        log_path.write_text(
            json.dumps(result, ensure_ascii=False, indent=2), encoding="utf-8"
        )
    except Exception as e:
        logger.debug(f"[LOG] write failed: {e}")

    result["feedback"] = {
        "summary": llm_text,
        "provider": provider_used,
        "model": (llm_model or settings.LLM_DEFAULT_MODEL),
    }

    return result


def _map_to_delegate(
    provider: str, extra: Dict[str, any]
) -> Tuple[str, Dict[str, any]]:
    """
    Routerë¡œë¶€í„° ë°›ì€ provider/vendorë¥¼ Delegateê°€ ì´í•´í•˜ëŠ” í˜•íƒœë¡œ ì–´ëŒ‘íŠ¸.
    - "gateway": ê²Œì´íŠ¸ì›¨ì´ë¡œ í¬ì›Œë”© (vendorëŠ” extra["vendor"]ì— í¬í•¨ë˜ì–´ ë“¤ì–´ì˜´)
    - "compat" : OpenAI-í˜¸í™˜ REST (base_url/api_key í•„ìš”)
    - "openai":  SDK ê²½ìœ 
    - ê·¸ ì™¸     : gatewayë¡œ í´ë°±
    """
    vendor = extra.get("vendor", "openai")
    if provider == "gateway":
        return "gateway", {"vendor": vendor, **extra}
    if provider == "compat":
        return "compat", {"vendor": vendor, **extra}
    if provider == "openai":
        return "openai", {**extra}
    return "gateway", {"vendor": vendor, **extra}


# s3 ë„ì…ì‹œ ì‚¬ìš©í•  service ë‹¨ ì½”ë“œ
def analyze_from_url(
    s3_url: str,
    side: str = "right",
    min_vis: float = 0.5,
    norm_mode: NormMode = NormMode.auto,
    llm_provider: str = settings.LLM_DEFAULT_PROVIDER,
    llm_model: Optional[str] = None,
    llm_api_key: Optional[str] = None,
) -> dict:
    """S3/HTTP ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ í›„ ë™ì¼ íŒŒì´í”„ë¼ì¸ ìˆ˜í–‰"""
    downloads = settings.DOWNLOADS_DIR
    downloads.mkdir(parents=True, exist_ok=True)

    filename = f"downloads/{uuid.uuid4().hex[:8]}.mp4"

    with requests.get(s3_url, stream=True) as r:
        r.raise_for_status()
        with open(filename, "wb") as f:
            shutil.copyfileobj(r.raw, f)

    return analyze_swing(
        str(filename),
        side=side,
        min_vis=min_vis,
        norm_mode=norm_mode,
        llm_provider=llm_provider,
        llm_model=llm_model,
        llm_api_key=llm_api_key,
    )


# ------------ Private ------------
def _infer_metrics_from_phase(phase_metrics: Dict[str, Dict[str, float]]) -> list:
    """ì„¤ì •ì´ ì—†ì„ ë•Œ, ê´€ì¸¡ëœ í˜ì´ì¦ˆ í•­ëª©ë“¤ì—ì„œ metric ë¦¬ìŠ¤íŠ¸ ìƒì„±"""
    keys = set()
    for vals in phase_metrics.values():
        keys.update(vals.keys())
    return sorted(keys)


# ëŸ°íƒ€ì„ QC + í´ë°± (bins ìŠ¤í‚¤ë§ˆ ê¸°ì¤€)
def _has_metric_block_like(d: dict) -> bool:
    """ë§ë‹¨ì— settings.THRESH_REQUIRED_KEYS êµ¬ì¡°ë¥¼ ë§Œì¡±í•˜ëŠ” ë¸”ë¡ì´ ì¡´ì¬í•˜ëŠ”ì§€ ê²€ì‚¬"""
    if not isinstance(d, dict):
        return False
    if REQUIRED_KEYS.issubset(d.keys()):
        return True
    for v in d.values():
        if isinstance(v, dict) and _has_metric_block_like(v):
            return True
    return False


def _is_thresholds_usable(data: dict) -> bool:
    """ê°€ë²¼ìš´ ëŸ°íƒ€ì„ QC: empty/ì˜ëª»ëœ bins/ìŒìˆ˜ n ë“± ìµœì†Œí•œì˜ ì²´í¬"""
    if not isinstance(data, dict) or not data:
        return False
    if not _has_metric_block_like(data):
        return False

    ok_bins = False
    ok_n = False

    def _walk(d: dict):
        nonlocal ok_bins, ok_n
        for _, v in d.items():
            if isinstance(v, dict) and REQUIRED_KEYS.issubset(v.keys()):
                bins = v.get("bins", [])
                if isinstance(bins, list) and len(bins) >= 2:
                    if all(isinstance(b, (int, float)) for b in bins):
                        if all(bins[i] >= bins[i - 1] for i in range(1, len(bins))):
                            ok_bins = True
                n = v.get("n", None)
                if isinstance(n, int) and n >= 0:
                    ok_n = True
            elif isinstance(v, dict):
                _walk(v)

    _walk(data)
    return ok_bins and ok_n


def _recent_threshold_candidates() -> list[Path]:
    """CONFIG_DIR ì•„ë˜ *_thresholds.json ì¤‘ currentê°€ ê°€ë¦¬í‚¤ëŠ” ì‹¤ì œ íŒŒì¼ì„ ì œì™¸í•˜ê³  ìµœì‹ ìˆœìœ¼ë¡œ ë°˜í™˜"""
    base = settings.CONFIG_DIR
    current = base / "thresholds_current.json"
    try:
        current_real = current.resolve(strict=True) if current.exists() else None
    except Exception:
        current_real = None

    pattern = str(base / "*_thresholds.json")
    paths = [Path(p) for p in glob.glob(pattern)]
    paths = [p for p in paths if p.is_file()]
    if current_real:
        paths = [p for p in paths if p.resolve() != current_real]
    paths.sort(key=lambda p: p.stat().st_mtime, reverse=True)
    return paths


def _by_view(data: dict, by: Optional[str]) -> dict:
    """íŒŒì¼ êµ¬ì¡°(by='phase'|'club'|'overall')ì— ë§ì¶° ì„œë¸Œë·° ë°˜í™˜"""
    if by is None:
        return data
    by = str(by).lower()
    if by == "overall":
        return data.get("overall") or data
    elif by in ("phase", "club"):
        return data
    return data


# Thresholds ë¡œë”©
# 1) current fhem -> qc í†µê³¼ì‹œ ì‚¬ìš©
# 2) ì‹¤íŒ¨ ì‹œ ìµœê·¼ë³¸ ìˆœíšŒí•˜ë©´ì„œ ì²˜ìŒë³¸ í†µê³¼ë³¸ ì‚¬ìš©
# 3) ëª¨ë‘ ì‹¤íŒ¨ì‹œ dict return
def _load_thresholds(by: Optional[str] = None) -> dict:
    """
    thresholds_current.json(ë˜ëŠ” ìµœì‹ ë³¸)ì—ì„œ by ì„¹ì…˜('phase'|'club'|'overall') í˜•íƒœë¥¼ ë°˜í™˜.
    íŒŒì¼ êµ¬ì¡°ëŠ” ìƒì„± ìŠ¤í¬ë¦½íŠ¸ì— ë”°ë¼:
      - by=phase:  { "P2": {...}, "P3": {...}, ... }
      - by=club:   { "iron": {...}, "driver": {...}, ... }
      - by=overall:{ "overall": {...} }
    """
    path = rf.thresholds_path()
    data = {}

    try:
        data = json.loads(Path(path).read_text(encoding="utf-8"))
    except Exception as e:
        logger.warning(f"[THRESH] failed to load current {path}: {e}")

    if qc_thresholds_usable(data, REQUIRED_KEYS):
        return _by_view(data, by)

    logger.warning("[THRESH] current unusable. trying recent archives...")

    for cand in _recent_threshold_candidates():
        try:
            cand_data = json.loads(cand.read_text(encoding="utf-8"))
        except Exception as e:
            logger.warning(f"[THRESH] skip {cand.name}: load error {e}")
            continue
        if qc_thresholds_usable(cand_data, REQUIRED_KEYS):
            logger.info(f"[THRESH] fallback -> {cand.name}")
            return _by_view(cand_data, by)

    logger.error("[THRESH] no usable thresholds found. use empty.")
    return {}


# bins â†’ min / max ì–´ëŒ‘íŠ¸ (ë£° í˜¸í™˜)
def _range_from_bins(
    block: dict, qlow: float, qhigh: float
) -> Optional[Tuple[float, float]]:
    """bins ì—£ì§€ë¥¼ í¼ì„¼íƒ€ì¼ êµ¬ê°„ìœ¼ë¡œ ë³€í™˜ (settings.THRESH_QLOW/HIGH ì‚¬ìš©)"""
    if not isinstance(block, dict) or not REQUIRED_KEYS.issubset(block.keys()):
        return None

    bins = block.get("bins")

    if not isinstance(bins, list) or len(bins) < 2:
        return None

    if len(bins) == 2:
        return float(bins[0]), float(bins[1])

    m = len(bins)
    lo_idx = max(0, min(m - 1, int(qlow * (m - 1))))
    hi_idx = max(0, min(m - 1, int(qhigh * (m - 1))))
    lo = float(bins[min(lo_idx, hi_idx)])
    hi = float(bins[max(lo_idx, hi_idx)])

    if lo == hi:
        return None

    return lo, hi


def _adapt_thresholds_bins_to_ranges(thr: dict, qlow: float, qhigh: float) -> dict:
    """ì¤‘ì²© êµ¬ì¡°(phase/club/overall) ë‚´ metric blockë“¤ì„ {min,max}ë¡œ ë³€í™˜"""
    return adapt_bins_to_ranges(thr, qlow=qlow, qhigh=qhigh, required_keys=REQUIRED_KEYS)


# ì…ë ¥ ì˜ìƒ í‘œì¤€í™”
def _do_preprocess(src_path: str, mode: NormMode):
    """
    ì…ë ¥ ì˜ìƒ í‘œì¤€í™”:
      - basic: ì¬ì¸ì½”ë”©
      - pro: HW ì¸ì½”ë”©/ìŠ¤ë§ˆíŠ¸ì¹´í”¼
      - auto: proâ†’ì‹¤íŒ¨ì‹œ basic
    """
    dst_dir = settings.NORMALIZED_DIR
    dst_dir.mkdir(parents=True, exist_ok=True)
    dst_path = dst_dir / f"{uuid.uuid4().hex[:8]}.mp4"

    t0 = time.perf_counter()
    used_mode = None

    fps = settings.VIDEO_FPS
    height = settings.VIDEO_HEIGHT
    mirror = settings.VIDEO_MIRROR

    try:
        if mode == NormMode.basic:
            normalize_video(src_path, dst_path, fps=fps, height=height, mirror=mirror)
            used_mode = "basic"
        elif mode == NormMode.pro:
            normalize_video_pro(
                src_path, dst_path, fps=fps, height=height, mirror=mirror
            )
            used_mode = "pro"
        else:
            try:
                normalize_video_pro(
                    src_path, dst_path, fps=fps, height=height, mirror=mirror
                )
                used_mode = "pro"
            except Exception:
                normalize_video(
                    src_path, dst_path, fps=fps, height=height, mirror=mirror
                )
                used_mode = "basic"

    except FileNotFoundError as e:
        raise HTTPException(status_code=404, detail=f"input not found: {e}") from e

    except RuntimeError as e:
        raise HTTPException(status_code=500, detail=f"preprocess failed: {e}") from e

    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"unexpected preprocess error: {e}"
        ) from e

    finally:
        ms = int((time.perf_counter() - t0) * 1000)

    return str(dst_path), used_mode, ms


def _dedupe_phases(phases: Dict[str, int]) -> Dict[str, int]:
    """
    ì„œë¡œ ë‹¤ë¥¸ í˜ì´ì¦ˆê°€ ê°™ì€ í”„ë ˆì„ ì¸ë±ìŠ¤ë¥¼ ê°€ë¦¬í‚¤ëŠ” ê²½ìš°ë¥¼ ì •ë¦¬.
    ì •ì±…: ì• ìˆœì„œ(P2â†’P9) ìš°ì„  ì±„íƒ, ì¤‘ë³µ ì¸ë±ìŠ¤ê°€ ë’¤ì—ì„œ ë‚˜ì˜¤ë©´ ë²„ë¦¼.
    """
    order = settings.THRESH_PHASES
    seen = set()
    out: Dict[str, int] = {}
    for p in order:
        idx = phases.get(p)
        if idx is None:
            continue
        if idx in seen:
            continue
        seen.add(idx)
        out[p] = idx
    return out